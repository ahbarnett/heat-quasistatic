\documentclass[10pt]{article}
\oddsidemargin = 0.2in
\topmargin = -0.5in
\textwidth 6in
\textheight 8.5in

\usepackage{graphicx,bm,hyperref,amssymb,amsmath,amsthm}
\usepackage{algorithmic,xcolor}

% -------------------------------------- macros --------------------------
% general ...
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\ben}{\begin{enumerate}}
\newcommand{\een}{\end{enumerate}}
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\bea}{\begin{eqnarray}} 
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\ba}{\begin{align}} 
\newcommand{\ea}{\end{align}}
\newcommand{\bse}{\begin{subequations}} 
\newcommand{\ese}{\end{subequations}}
\newcommand{\bc}{\begin{center}}
\newcommand{\ec}{\end{center}}
\newcommand{\bfi}{\begin{figure}}
\newcommand{\efi}{\end{figure}}
\newcommand{\ca}[2]{\caption{#1 \label{#2}}}
\newcommand{\ig}[2]{\includegraphics[#1]{#2}}
\newcommand{\bmp}[1]{\begin{minipage}{#1}}
\newcommand{\emp}{\end{minipage}}
\newcommand{\pig}[2]{\bmp{#1}\includegraphics[width=#1]{#2}\emp} % mp-fig, nogap
\newcommand{\bp}{\begin{proof}}
\newcommand{\ep}{\end{proof}}
\newcommand{\ie}{{\it i.e.\ }}
\newcommand{\eg}{{\it e.g.\ }}
\newcommand{\etal}{{\it et al.\ }}
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pdc}[3]{\left. \frac{\partial #1}{\partial #2}\right|_{#3}}
\newcommand{\infint}{\int_{-\infty}^{\infty} \!\!}      % infinite integral
\newcommand{\tbox}[1]{{\mbox{\tiny #1}}}
\newcommand{\mbf}[1]{{\mathbf #1}}
\newcommand{\half}{\mbox{\small $\frac{1}{2}$}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\RR}{\mathbb{R}^2}
\newcommand{\ve}[4]{\left[\begin{array}{r}#1\\#2\\#3\\#4\end{array}\right]}  % 4-col-vec
\newcommand{\vt}[2]{\left[\begin{array}{r}#1\\#2\end{array}\right]} % 2-col-vec
\newcommand{\bigO}{{\mathcal O}}
\newcommand{\qqquad}{\qquad\qquad}
\newcommand{\qqqquad}{\qqquad\qqquad}
\DeclareMathOperator{\Span}{Span}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\re}{Re}
\DeclareMathOperator{\vol}{vol}
\newtheorem{thm}{Theorem}
\newtheorem{cnj}[thm]{Conjecture}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{pro}[thm]{Proposition}
\newtheorem{rmk}[thm]{Remark}
% this work...
\newcommand{\pO}{{\partial\Omega}}
\newcommand{\LpO}{\Delta_\pO}
\newcommand{\eps}{\epsilon}
\newcommand{\dn}{\partial_n}
\newcommand{\dt}{\partial_t}
\newcommand{\LTO}{{L^2(\Omega)}}
\DeclareMathOperator{\Lap}{Lap}



\begin{document}

\title{Quasistatic correction in powers of reciprocal diffusivity for heat initial boundary value problems}

\author{Alex H. Barnett}
\date{\today}
\maketitle

\begin{abstract}
  Motivated by a cell polarization model of Diegmiller et al (2018),
  we consider IBVPs for the heat equation
  in the case of large diffusivity $\kappa$.
  We sketch a numerical boundary integral method that achieves
  arbitrary order accuracy in $\eps = 1/\kappa \ll 1$,
  exploiting the fact that in this case the heat equation has a short memory.
  This replaces history-dependent heat potentials in favor of a
  the quasi-static solution plus a sequence of corrections each involving
  one local derivative in time and one static Poisson solve.
  We show that initial data is irrelevant for times beyond $\bigO(\eps)$.
  Neglecting discretization errors, the 
  result matches boundary data exactly but does not exactly solve the PDE.
  The latter's residual is uniformly $\bigO(\eps^p)$
  if $p-1$ correction steps are done, i.e.\ it gains one order of $\eps$
  per correction step.
  Some stability results on IBVP solutions with respect to volume driving
  are thus needed to convert this to a bound on the solution error.

  We consider the Dirichlet and (trickier) Neumann cases,
  the latter being closer to the cell model.
  Interior discretization and boundary-only implementations are sketched.
\end{abstract}

\section{Introduction}

We are motivated by a coupled cell polarization problem \cite{diegmiller18}
where the interior heat equation has Neumann boundary conditions
(a net flux) given as a nonlinear function of the local interior and surface concentrations.
Here the bulk diffusivity is at least $10^2$ times larger than the surface diffusivity, allowing a
numerical quasistatic approximate solution which
requires surface diffusion alone (see other notes and \cite{diegmiller18}).
Yet to achieve higher accuracy, in general shapes in 3D,
a possibility would be a full heat-equation solver; this would require
a lot of technology, including short-time surface quadratures and modal history compression in the style of Greengard, Strain, Li, Wang, etc.
We present a simpler alternative, which trades time-history for
a volumetric spatial grid for static spatial solves, achieving high-order
accuracy for the case of large bulk diffusivity.

We use simple linear IBVPs to present the idea, for a fixed
bounded smooth domain $\Omega \in \R^d$, in general dimension $d$.


% DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD
\section{The case of time-dependent Dirichlet data}

Given a fixed inverse diffusivity $\eps\ll 1$,
and final time $T$,
we wish to efficiently solve the IBVP
\bea
\eps\dot{u} - \Delta u &=& 0    \qquad \mbox{ in } \Omega\times (0,T)
\label{pde}
\\
u  &=& f  \qquad \mbox{ on } \pO \times (0,T)
\label{bc}
\\
u(\cdot, 0)    &=&  0 \qquad \mbox{ in } \Omega
\label{ic}
\eea
where dot denotes $\partial/\partial t$, and the given
time-dependent boundary data is $f(x,t)$,
with the usual compatibility $f=0$ on  $\pO\times\{t=0\}$.
It is assumed that $f$ is smooth on the unit timescale, in particular
being oblivious to $\eps$.

Non-zero initial data is not needed here,
because the effect of any initial data decays away
in time $\bigO(\eps)$ (see other notes on asymptotic analysis).
This can be seen by writing $\phi_j$ as the orthonormal eigenfunctions
of $-\Delta$ in $\Omega$ with Dirichlet BCs, and $\lambda_j$
the coresponding eigenvalues, and noting that
$$
u(x,t) = \sum_{j=1}^\infty c_j e^{-\lambda_jt/\eps} \phi_j(x)
$$
satisfies \eqref{pde} with zero BCs and initial data $u(\cdot,0)=w$,
for coefficients $c_j = \langle \phi_j, w \rangle$.

Our approximate method will solve \eqref{bc}--\eqref{ic}, but
not solve \eqref{pde} exactly.
We need to know how that residual controls the overall solution error.

\begin{lem}[Stability with respect to volume driving]
  Let $u$ solve the inhomogeneous IBVP
\bea
\eps\dot{u} - \Delta u &=& g    \qquad \mbox{ in } \Omega\times (0,T)
\label{pdeg}
\\
u  &=& 0  \qquad \mbox{ on } \pO \times (0,T)
\label{bc0}
\\
u(\cdot, 0)    &=&  0 \qquad \mbox{ in } \Omega
\eea
where $\|g(\cdot,t)\|_\LTO \le M$ for all $t\in(0,T)$.
Then
\be
\|u(\cdot,t)\|_\LTO \;\le\;
\frac{1}{\lambda_1}\sup_{t\in(0,T)}\|g(\cdot,t)\|_\LTO~.
\label{gstab}
\ee
\label{l:gstab}
\end{lem}
\begin{proof}
We use the energy method.
Writing $L(t):=\|u(\cdot,t)\|_\LTO$, then by \eqref{pdeg},
$$
\frac{\eps}{2}\dt(L^2) = \eps\int_\Omega u \dot u = \int_\Omega
u\Delta u + \int_\Omega g u
$$
The eigenfunction expansion
$u(\cdot,t) = \sum_{j=1}^\infty a_j \phi_j$
bounds $\int_\Omega u\Delta u = -\sum_{j=1}^\infty \lambda_1 a_j^2
\le -\lambda_1 L^2$.
Applying this, and Cauchy--Schwartz to the $gu$ term, with $M:=\sup_{t\in(0,T)}\|g(\cdot,t)\|_\LTO$,
we get
$$
\eps L\dot L \le -\lambda_1 L^2 + ML~,
$$
with initial condition $L(0)=0$.
Thus $L(t)$ is upper-bounded by the solution to the ODE equality,
which is (by cancelling $L$),
$$
L(t) = \frac{M}{\lambda_1} (1 - e^{-\lambda_1 t / \eps})~.
$$
This never exceeds $M/\lambda_1$.
\end{proof}

Note that the right-hand side of \eqref{gstab} doesn't involve a factor $1/\eps$,
which is surprising because physically the driving
(power density input)
in \eqref{pdeg} is $g/\eps$, i.e., large.
However, the diffusivity $1/\eps$ and Dirichlet BCs suck
the heat out on a rapid timescale $\bigO(\eps)$, so that it doesn't have time to build up in the interior.
For unit-sized domains $\Omega$, $\lambda_1=\bigO(1)$, and cannot be
small by the Faber--Krahn inequality.


\subsection{Correction to arbitrary order via static solves}

Now to the method for the IBVP \eqref{pde}--\eqref{ic}.
Let $u_1$ solve the quasistatic Laplace problem which sets $\eps=0$
in \eqref{pde}.
Its residual is thus $(\eps\dt-\Delta)u_1 = \eps \dot u_1 =: \eps r_1$.
So, applying Lemma~\ref{l:gstab} to $u_1-u$
shows that $u_1$ is an $\bigO(\eps)$ accurate solution
to the IBVP.
Its cost is one Laplace solve per timestep (and since no evolution
equations are solved, the timestep is dictated only by the user's desired
evaluation time grid).
It is the Dirichlet equivalent of the quasistatic approximation
used in \cite{diegmiller18}.

Now let $v_1$ solve the static Poisson equation $\Delta v_1 = r_1$ with
BC $v_1=0$ on $\pO$. Recall that $r_1=\dot u_1$ is a known function
on $\Omega \times (0,T)$, so a Poisson solve is needed at each time $t$.
Consider the corrected trial function
$u_2 := u_1 + \eps v_1$. Its residual cancels by construction as follows,
$$
(\eps\dt-\Delta)(u_1 +\eps v_1) = \eps r_1 - \eps \Delta v_1 +\eps^2 \dot v_1 =
\eps^2 \dot v_1 =: \eps^2 r_2~.
$$
Applying Lemma~\ref{l:gstab} to $u_2-u$
shows that $u_2$ is an $\bigO(\eps^2)$ accurate solution
to the IBVP.
One way to phrase its extra cost (per timestep) over $u_1$ as
one Poisson solve plus one time-derivative;
we study the actual cost of implementations below.
It formally requires {\em no history information} if $f$, $\dot f$, and
$\ddot f$ are provided at each desired output time $t$.
It would get around 5-digit accuracy for the
$\eps\approx 0.003$ in the cell polarization application in \cite{diegmiller18},
which is probably adequate.

For any target evaluation time $t$, one may iterate the above
to get any higher-order accuracy $p\ge1$. Here's the formal procedure
(see below for implementations, which move time-derivatives to different
places):

\vspace{1ex}
\colorbox[rgb]{0.9,0.9,0.9}{%
\begin{minipage}{0.9\textwidth}
\begin{algorithmic}
  \STATE let $v_0 := u_1$ be given as the quasistatic Laplace solution to $f$
  \FOR{$k=1,\dots,p-1$}
  \STATE take time-derivative of volume function: \; $r_{k} \gets \dot v_{k-1}$
  \STATE solve Poisson equation with this data: \;\;\; $\Delta v_k = r_k$ in $\Omega$, with $v_k=0$ on $\pO$
  \ENDFOR
\end{algorithmic}
\end{minipage}
}%
\vspace{1ex}

Then the trial solution
\be
u_p := \sum_{k=0}^{p-1} \eps^k v_k
\label{up}
\ee
matches the BC and IC, and has PDE
residual $(\eps\dt-\Delta)u_p = \eps^p \dot v_{p-1}$,
and thus by Lemma~\ref{l:gstab} is an $\bigO(\eps^p)$ accurate solution
to the IBVP.
All correction operations are local in time.
Choosing even $p=4$ would get around 10-digit accuracy for the $\eps$
mentioned above.

Here are equivalent formulae for the general $p$ case.
Let $\Lap_D: C(\pO) \to C(\Omega)$ be the solution operator for the Dirichlet
Laplace equation in $\Omega$, and let $\Delta_0^{-1} : C^k(\Omega) \to
C^{k+2}(\Omega)$ be the solution operator for the Poisson equation with
zero Dirichlet boundary data. When acting on functions of
space and time, each operator is taken to act locally in time
(i.e., independently on time slices).
Then another formal way to write \eqref{up} is, recalling $u_1=v_0=\Lap_D f$ is
the quasistatic solution,
\bea
u_p &=& v_0 + \eps \Delta_0^{-1} \dot v_0 + \eps^2 \Delta_0^{-2} \ddot v_0 +
\dots + \eps^{p-1} \Delta_0^{-(p-1)} \dt^{p-1} v_0
\\
&=&
\Lap_D f + \eps \Delta_0^{-1} \Lap_D \dot f + \ldots
+ \eps^{p-1} \Delta_0^{-(p-1)} \Lap_D \dt^{(p-1)} f
~.
\label{upformal}
\eea
There are many other ways to write it because $\dt$ and spatial solves
commute.


\subsection{Implementation I: interior discretization (sketch)}

For spatially simpler problems,
keeping in mind $d=2$ or $d=3$ dimensional applications,
it is practical to fix a
volume quadrature scheme over $\Omega$ with $\bigO(n^d)$ nodes,
$n$ being the number of nodes per linear dimension.
$\pO$ is discretized with $\bigO(n^{d-1})$ nodes.
For simplicity imagine the boundary data $f(\cdot,t_j)$ is supplied on the boundary nodes on a regular time grid $t_j=j\delta$, $j\in\Z$, $\delta>0$.
We will not need $f$'s derivatives to be supplied.
Pick $p$, the desired accuracy order in $\eps$.
We wish to evaluate the approximate solution on the same time grid.

Our solvers are (we ignore close-evaluation aspects for now):
\bi
\item
  For $\Lap_D$, a boundary-integral (BIE) solver followed by FMM evaluation on
  interior nodes. Cost $\bigO(n^d)$, dominated by interior evaluation.
\item
  For $\Delta_0^{-1}$, FMM evaluation from interior to boundary,
  then correction by a BIE, followed by box-code plus boundary density
  evaluation back to interior.
  Cost $\bigO(n^d)$, dominated by interior-to-interior box-code, I guess.
\ei

The algorithm exploits that the time-derivatives can be pushed to the end:
\ben
\item
  For each timestep $j$, fill interior data $w_0(\cdot,t_j)=\Lap_D f(\cdot,t_j)$,
  then for $k=1,\ldots,p-1$,
  iterate $w_k(\cdot,t_j)=\Delta_0^{-1} w_{k-1}(\cdot,t_j)$, storing them all
  on interior nodes.
\item
  Apply a set of finite-difference rules (eg from reading off the lowest $p$ derivatives of a local Lagrange interpolation)
  in the time direction, pointwise for each interior node,
  to compute
  $v_k(\cdot,t_j) = \dt^k w_k(\cdot,t_j)$, for $k=0,\ldots,p-1$.
\item
  Sum the $v_k$ according to \eqref{up} at each node at each timestep.
\een

The result is the interior solution on the time grid at all interior nodes.
Multiple $\eps$ choices could be spat out in this way for free
(in the linear case presented).
Boundary normal-derivative
data could be spat out of each Poisson solve too, but the interior
values are actually needed in all but the last Poisson solve.
The cost is $\bigO(pn^d)$ (dominated by $p-1$ Poisson solves)
per timestep.
Practically, one will sweep through the timesteps in order.
Since the FD stencil width is of order $p$, at least,
to read out $p-1$ derivatives, one needs storage $p^2n^d$,
ie about $p^2$ copies of the volume grid.
So, $p$ cannot be large.
If a marching scheme (for a nonlinear coupled problem) were in play
that generated the data $f$ on the fly,
a BDF would be needed for step 2 above.

Note that the polyharmonic solves evident in \eqref{upformal}
are captured by the repeated Poisson solves. The possible $p^2$ cost is
thus avoided.

Note that digit loss is expected with higher time-derivatives,
but they are hit by increasing powers of $\eps$, so, I imagine this
is not a problem.
I have not thought about the trade-off between order of timestep $\delta$
accuracy vs $\eps$-correction-order.

{\bf Simplest case: $p=2$.}
Getting $\bigO(\eps^2)$ accuracy needs one Laplace solve
and one Poisson solve per timestep, and a FD (or BDF) formula
to read off $v_1 = \dt w_1$ at all interior nodes.
If the boundary Neumann data (and no interior solution) is needed,
the box-code becomes a plain FMM from interior to boundary
(apart from near-boundary corrections), which will be much faster than
an interior-interior box code.
This is quite a reasonable scheme, basically two
BIE solves plus two interior-to-boundary FMMs per timestep.



\subsection{Implementation II: all on the boundary (sketch)}

Since the heat equation is homogeneous, only boundary values
(specifically, the complementary data, which is Neumann here)
are needed to know the interaction with the surface in a practical
nonlinear coupled problem.
We can entirely avoid interior nodes,
at a cost of polyharmonic BIE solves.

{\bf Simplest case: $p=2$.}
Recall $v_0$ solves, at each timestep, $\Delta v_0 = f$ with $v_0=0$ on $\pO$.
Thus $\dn v_0$ may be computed by a 2nd-kind BIE solver, e.g.\ for large problems in $\bigO(n^{d-1})$ effort via FMM+GMRES.
Now $v_1$ solves, at each timestep, the biharmonic equation
\bea
\Delta^2 v_1 &=& 0 \qquad \mbox{ in } \Omega
\\
\Delta v_1 &=& \dot f \qquad \mbox{ on } \pO
\\
v_1 &=& 0 \qquad \mbox{ on } \pO~.
\eea
This boundary condition is of inhomogeneous Navier type.\footnote{In the 1D case this is physically a rod mounted at points with sprung pivots transmitting given torques at these points, and zero interior loading.}
Thus $\dn v_1$ may be also computed by a 2nd-kind BIE solver, e.g.\ in $\bigO(n^{d-1})$ effort via FMM plus an iterative solver, but the biharmonic formulation and FMM are more complicated.
For small problems with a fixed geometry, the boundary solution operators
could be prestored either in dense ($n^{d-1} \le 10^4$)
or rank-structured compressed
($n^{d-1} \le 10^6$) form.
The boundary solution $\dn u_2 := \dn v_0 + \eps \dn v_1$ is then $\bigO(\eps^2)$
accurate.

{\bf Higher-order cases.}
Higher $p$ requires polyharmonic BVP solutions up to order $\Delta^p$.
Namely, $v_k$ solves, at each timestep,
\bea
\Delta^k v_k &=& 0 \qquad \mbox{ in } \Omega
\\
\Delta^{k-1} v_k &=& \dt^{k-1} f \qquad \mbox{ on } \pO
\\
\Delta^{k-2} v_k &=& 0 \qquad \mbox{ on } \pO
\\
\dots &&\dots
\\
v_k &=& 0 \qquad \mbox{ on } \pO~.
\eea
Even $p=3$ seems impractical in $d=3$ dimensions.

In a nonlinear coupled time-marching setting,
$\dot f$, $\ddot f$, etc, could be approximated via a low-order
BDF.

\subsection{Implementation III: eigenmodes all on the boundary (sketch)}

This is far-fetched, and only possible for spatially smooth enough $f$,
and a fixed shape.
It will have an expensive precomputation phase,
but perhaps fast evolution compared to the above,
especially for larger $\eps$ where a large order $p$ would help.
Find the boundary data of all Dirichlet eigenmodes $\dn \phi_j$
for eigenvalues $\lambda_j \le E$, for some convergence parameter $E$.
Weyl tells us there are $N=\bigO(E^{d/2})$ of them.

*** TO DO

The point is that the Laplace and polyharmonic BVP solves
are all equally
simple sums of rank-1 projectors in $L^2(\pO)$, in the eigenbasis.
No BIE quadratures, close evaluations, or biharmonic are needed.

*** study convergence rate, may be unacceptable.


% NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN
\section{The Neumann case}

For a given flux boundary data $f$ entering the domain,
Fick's law at the boundary gives the IBVP
\bea
\eps\dot{u} - \Delta u &=& 0    \qquad \mbox{ in } \Omega\times (0,T)
\label{pden}
\\
\dn u  &=& \eps f  \qquad \mbox{ on } \pO \times (0,T)
\label{bcn}
\\
u(\cdot, 0)    &=&  0 \qquad \mbox{ in } \Omega
\eea
where $\dn = \mbf{n}\cdot\nabla$ where $\mbf{n}$ is the unit surface
normal facing out of $\Omega$.
A crucial difference between this IBVP and the quasistatic case
is that $f$ need not satisfy zero net flux $\int_\pO f = 0$.
Indeed the net flux $f$ is $\bigO(1)$, resulting in a solution $u$ that
is constant to $\bigO(\eps)$, but that constant can change in time
at an $\bigO(1)$ rate.
Specifically, for any $\eps>0$,
\be
\dt \int_\Omega u = \int_\pO f(\cdot,t)~, \qquad t>0
\label{cons}
\ee
which easily follows from the PDE and the divergence theorem.


%*** is the Laplace consistency cond on $f$ enforced at each time?
%Otherwise $u$ shoots up at speed $1/\eps$ which is huge, and
%a smooth solution on unit timescales is impossible.
%In the cell application, consistency applies to order $\eps$.
%A weird set-up.

*** TO DO

The zero mode wreaks havoc, but makes getting $\bigO(\eps)$ easier
than the Dirichlet case since $v_0$ is constant,
so a particular Poisson solution may be written down, leaving just two Laplace BIE solves!

*** TO DO






\section{Discussion}

\bi
\item
  Clearly finite-difference schemes with explicit timestepping are
  a disaster, since $\delta t \le c \eps h^2$.
  Implicit is worth exploring; in fact higher-order
  implicit schemes may be related to the correction iteration \eqref{up}.
\item
  Taking arbitrarily high time derivatives of the BC data $f$ is dangerous
  and loses digits. A heat-potential scheme may not lose these digits,
  but is much more complicated to get correct.
\item
Strangely, if $f(x,\cdot) \in C^\infty((0,T))$,
taking $p\to\infty$ in \eqref{upformal} gives the formal Neumann series
\be
u_\infty := \Lap_D f + \eps \Delta_0^{-1} \dt \Lap_D f + \eps^2 \Delta_0^{-2} \dt^2 \Lap_D f + \dots
= (I - \eps \Delta_0^{-1} \dt)^{-1} \Lap_D f
\ee
whose meaning is obscure.
It is not a mere translation in time since it has no
reciprocal factorial factors. Its convergence a mystery
even for small $eps$, because $\dt$ is not a bounded operator
unless we can restrict $f$ to some fancy very smooth function space.
\item
  I have tried analogous $\eps$-expansions for heat potentials
  to solve the Dirichlet IBVP.
  However, the mass of the algebraic tails in time decays like
  fractional powers of $\eps$, and it is not obvious how to
  write the result as a perturbation from the quasistatic solution $u_1$.
  I am far from a numerical method there. In contrast the above seems
  quite simple.
  \ei


% BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
\bibliographystyle{abbrv}
\bibliography{localrefs}
\end{document}

